<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-cn" lang="zh-cn">
<head>
  <meta name="generator" content="Hugo 0.37.1" />

  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>HSVS-HTTP全流量可视化系统</title>

  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <link rel="stylesheet" href="css/styles.css">
  <link href="/index.xml" rel="alternate" type="application/rss+xml" title="HSVS-HTTP全流量可视化系统" />

</head>
<body>

<div class="sidebar">
    <div class="navigation">
        <div align="center">
    <img src="https://s1.ax1x.com/2018/04/02/CSA2sf.png" height=100 width=100>
</div>

        <h1 class="site-title"><a href="">HSVS-HTTP全流量可视化系统</a></h1>


        <nav class="internal">
            <ul>
    
        
            
    <li>
        <a href="#introduce">简介</a>
        <ul>
            
            
                <li><a href="#feature">功能特点</a></li>
            
                <li><a href="#history">更新历史</a></li>
            
        </ul>
    </li>



        
            
    <li>
        <a href="#install">安装</a>
        <ul>
            
            
                <li><a href="#install_standalone">单机版</a></li>
            
                <li><a href="#cluster_intra">集群-内网版*</a></li>
            
                <li><a href="#kafka_intra_kafka">集群-内网版KAFKA部署</a></li>
            
                <li><a href="#kafka_intra_nsq">集群-内网版NSQ部署</a></li>
            
                <li><a href="#kafka_intra_redis">集群-内网版REDIS部署</a></li>
            
                <li><a href="#install_pub">集群-公网版*</a></li>
            
        </ul>
    </li>



        
            
    <li>
        <a href="#usage">使用</a>
        <ul>
            
            
                <li><a href="#work">业务</a></li>
            
                <li><a href="#security">安全</a></li>
            
                <li><a href="#data_interface">数据接口</a></li>
            
                <li><a href="#ana_interface">分析接口</a></li>
            
        </ul>
    </li>



        
            
    <li>
        <a href="#appendix">附录</a>
        <ul>
            
            
                <li><a href="#dict">数据字典</a></li>
            
                <li><a href="#bug">BUG追踪</a></li>
            
                <li><a href="#FAQ">FAQ</a></li>
            
                <li><a href="#contact">联系我们</a></li>
            
        </ul>
    </li>



        
    
</ul>

        </nav>

        <nav class="external">
            <div class="external-title">河马安全团队</div>
            
            <ul id="shortcuts">
                
                <li>
                    <a href="" target="_blank" rel="noopener">HOME</a>
                </li>
                
                <li>
                    <a href="http://www.shellpub.com" target="_blank" rel="noopener">主站</a>
                </li>
                
            </ul>
            
        </nav>
    </div>

    <div class="version">
            generated on May 7, 2018
    </div>
</div>

<div class="content">
    
        
            
    <section class="page" id="introduce">
    <h1>
        <a href="#introduce">简介</a>
    </h1>
    <div class="content">
        <p>本项目名称为HSVS(HTTP STREAM VISUALIZATION SYSTEM), HTTP流量可视化系统。 本项目名称为HSVS，并没有直接称呼为流量分析系统；目的是将分析部分开放出来，让使用者使用自己的方法，自由的进行分析。</p>

<p>HTTP全流量分析目前已经在各大厂里比较普及了(BAT，携程，网易&hellip;)。 HTTP全流量分析相比之前单纯的WEB日志多了详细的请求头，完整的相应体，能分析出更多有用的东西。特别是随着<a href="https://en.wikipedia.org/wiki/Representational_state_transfer">RESTful</a>的流行，传统的WEB日志已经拿不到请求的真实响应(status code)了。</p>

<p>全流量分析涉及到一定的底层开发，还有分析系统开发，对于小企业有一定门槛，本项目旨在消除此门槛，让大家都能做到自由的获取HTTP全流量数据。 笔者所从事的信息安全行业对于HTTP全流量分析需求比较迫切。 HTTP流量分析既可以发现信息安全领域的问题，也可以在业务风控领域有所建树。 从信息安全的发展趋势来看，目前是从信息安全往企业安全和内容安全发展。 而HTTP全流量分析成为了企业安全和内容安全的重要组成部分。</p>

<div class="block note">
    <p>在使用本系统前建议了解的知识<br />
1. <a href="https://www.elastic.co">ELK</a><br />
2. <a href="https://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html">HTTP规范</a><br />
3. 建议掌握一些常见的kibana搜索知识(简单使用)<br />
4. 掌握常用分析算法和分析程序（例如使用spark进行分析）</p>

</div>


    </div>
</section>

    
            
                <section class="page" id="feature">
    <h1>
        <a href="#feature">功能特点</a>
    </h1>
    <div class="content">
        

<h2 id="特性">特性</h2>

<ul>
<li>一键部署</li>
<li>开箱即用</li>
<li>分析接口开放</li>
<li>数据接口开放</li>
<li>地理位置解析</li>
<li>真实IP提取</li>
<li>智能状态码、UID、手机号</li>
<li>支持流量镜像</li>
</ul>

<h2 id="项目结构">项目结构</h2>

<p>抓取模块</p>

<p>消息队列</p>

<p>基础分析程序</p>

<p>ES+kibna 分析展示模块</p>

    </div>
</section>

            
                <section class="page" id="history">
    <h1>
        <a href="#history">更新历史</a>
    </h1>
    <div class="content">
        

<h2 id="单机版更新历史">单机版更新历史</h2>

<ul>
<li>2018-04-03 单机版</li>
<li>2018-04-09 单机版 v1.1

<ul>
<li>修复-P混杂模式选项不能识别的BUG</li>
<li>修复IO过低时ElasticSearch程序启动过慢导致处理程序无法正常启动的BUG</li>
</ul></li>
<li>2018-04-30 单机版 v1.2

<ul>
<li>增强request.body，支持gzip/zlib压缩数据</li>
<li>修正抓包程序没有正常返回输出描述符的BUG，该BUG导致release程序崩溃</li>
<li>使用gcc -O2方式编译hcaplite</li>
<li>调整模板 response.body request.body request.url request.x-forwarded-for request.user-agent 修改为text方式索引, 关于keyword和text的差异请参考<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.5/breaking_50_mapping_changes.html">https://www.elastic.co/guide/en/elasticsearch/reference/5.5/breaking_50_mapping_changes.html</a></li>
<li>初步解决了上一个版本存在严重丢包的问题</li>
</ul></li>
</ul>

<h2 id="项目结构">项目结构</h2>

<p>抓取模块</p>

<p>消息队列</p>

<p>基础分析程序</p>

<p>ES+kibna 分析展示模块</p>

    </div>
</section>

            



        
            
    <section class="page" id="install">
    <h1>
        <a href="#install">安装</a>
    </h1>
    <div class="content">
        <div class="block note">
    <p>本项目分为三个版本</p>

<ol>
<li>单机版</li>
<li>集群内网版</li>
<li>集群公网版</li>
</ol>

</div>


    </div>
</section>

    
            
                <section class="page" id="install_standalone">
    <h1>
        <a href="#install_standalone">单机版</a>
    </h1>
    <div class="content">
        

<h2 id="适用场景">适用场景</h2>

<p>业务量较小的网站或者公司，完整集成包，开箱即用。</p>

<h2 id="需求">需求</h2>

<ol>
<li>空闲内存&gt;1.5GB (内置ES内存限制为1G， 如果内存较大可以手动修改，配置不要超过系统内存的一半)</li>
<li>tps &lt; 3000</li>
<li>cpu核心数&gt;=2</li>
</ol>

<h2 id="部署方式">部署方式</h2>

<p>1.流量镜像模式；</p>

<p><img src="https://s1.ax1x.com/2018/04/02/9z5bWt.png" alt="" /></p>

<p>2.直接在反向代理部署, 确保你的反向代理开启了X_FORWARD_FOF；</p>

<p><img src="https://s1.ax1x.com/2018/04/02/9z5HJI.png" alt="" /></p>

<p>3.如果使用了HTTPS，可以结合1，2两种方案进行, 在反向代理抓取HTTPS卸载之后的流量，在镜像抓取纯HTTP流量</p>

<h2 id="依赖">依赖</h2>

<ul>
<li><a href="http://www.docker.org.cn/book/docker/what-is-docker-16.html">docker</a></li>
</ul>

<h2 id="获取程序">获取程序</h2>

<p>官方源:</p>

<pre><code>docker  pull sort/hsvs-standalone
</code></pre>

<p>docker官方中国源(推荐):</p>

<pre><code>docker pull registry.docker-cn.com/sort/hsvs-standalone
</code></pre>

<h2 id="运行说明">运行说明</h2>

<ol>
<li><p>首先应当在您的环境下安装Docker</p></li>

<li><p>拉取镜像</p>

<p>docker pull sort/hsvs-standalone</p></li>

<li><p>运行</p></li>
</ol>
<div class="highlight"><pre style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">    
    <span style="color:#111">docker</span> <span style="color:#111">run</span> <span style="color:#f92672">-</span><span style="color:#111">d</span> <span style="color:#f92672">--</span><span style="color:#111">privileged</span><span style="color:#f92672">=</span><span style="color:#111">true</span> <span style="color:#f92672">--</span><span style="color:#111">net</span><span style="color:#f92672">=</span><span style="color:#111">host</span> <span style="color:#f92672">-</span><span style="color:#111">p</span> <span style="color:#ae81ff">5601</span><span style="color:#111">:</span><span style="color:#ae81ff">5601</span> <span style="color:#f92672">-</span><span style="color:#111">p</span> <span style="color:#ae81ff">9200</span><span style="color:#111">:</span><span style="color:#ae81ff">9200</span> <span style="color:#111">sort</span><span style="color:#f92672">/</span><span style="color:#111">hsvs</span><span style="color:#f92672">-</span><span style="color:#111">standalone</span> <span style="color:#f92672">-</span><span style="color:#111">f</span> <span style="color:#d88200"></span><span style="color:#d88200">&#39;tcp port 80&#39;</span> <span style="color:#f92672">-</span><span style="color:#111">i</span> <span style="color:#111">eth0</span> <span style="color:#f92672">-</span><span style="color:#111">P</span></code></pre></div>
<pre><code>docker参数说明

    -d 让docker镜像以后台守护进程的方式运行
    -p docker 端口，将docker内部的kibana
        和elasticsearch端口映射到主机
    --privilged=true 开启root权限，允许docker程序抓包
    --net=host 使用主机网络，这样docker里程序可以抓取主机流量

运行参数说明

    -i &lt;ethname&gt; 指定网卡名称 
    -f &lt;port filter&gt; 可选， 指定过滤端口信息，
        如果不加此选项默认会处理所有端口，
        这个选项在https反代抓包时很有用，过滤器语法同tcpdump语法
    -P 可选，开启混杂模式，在流量镜像模式抓包时使用，
</code></pre>

<p>4.创建kibana索引</p>

<pre><code>    单机版启动时间大约为1分钟后，系统中抓取到记录后打开kibana  
    http://&lt;你的主机IP&gt;:5601  
    点击左侧导航栏-&gt;Management-&gt;Index Patterns-&gt;Create Index Pattern
    在Index name or pattern中输入
    logstash-http-session-*
    在下面`Time Filter field name`中选择@timestamp
    点击Create完成创建, 下面两个[DEPRECATED]选项不要勾选！
    点击左侧导航栏Discover即可查看抓取到的流量
</code></pre>

<p><img src="https://s1.ax1x.com/2018/04/05/C9b4VP.png" alt="" /></p>

<pre><code>注: 如果没有弹出择@timestamp, 点击refresh field几次，
如果多次尝试没有出现请检查安装环境是否有误, 为了保证性能，此处采用批量提交，首次提交可能在1分钟之后，请耐心长还是
</code></pre>

    </div>
</section>

            
                <section class="page" id="cluster_intra">
    <h1>
        <a href="#cluster_intra">集群-内网版*</a>
    </h1>
    <div class="content">
        

<h2 id="适用场景">适用场景</h2>

<p>企业内网，IDC机房。
可以采用两种部署模式：<br />
1. 流量镜像模式；<br />
2. 直接在反向代理部署；<br />
3. 如果使用了HTTPS，可以结合1，2两种方案进行</p>

<h2 id="依赖">依赖</h2>

<ul>
<li>docker</li>
<li>elasticsearch(建议版本&gt;=5.0)</li>
<li>kibana(建议版本&gt;=5.0)</li>
<li>消息队列(推荐kafka, 如无可以使用redis/nsq替代)</li>
<li>elasticsearch XPack插件(可选)</li>
</ul>

<h2 id="环境要求">环境要求</h2>

<ul>
<li>镜像流量建议单独部署到物理机（根据实际情况内存需求&gt;tps*3000 Byte)，如果流量过大需要使用网络分流器</li>
<li>消息中间件kafka (可选nsq和redis)</li>
<li>ElasticSearch 集群</li>
</ul>

<h2 id="节点描述">节点描述</h2>

<ul>
<li>hcap 抓取模块，负责将http流还原成json数据</li>
<li>消息中间件(kafka/nsq/redis)</li>
<li>mbridge，负责将json数据从消息中间件中处理写入ElasticSearch</li>
<li>ElasticSearch + kibana 最终的消息存储和可视化的显示</li>
<li>analyzed(尚未开发完成) 负责实时分析流量，根据配置的（安全或者风控）规则出处命中结果到ElasticSearch</li>
</ul>

<h2 id="方案一-强烈建议-使用kafka消息中间件部署拓扑图">方案一(强烈建议), 使用kafka消息中间件部署拓扑图</h2>

<p>优点: kafka吞吐率，稳定性，持久化很优秀，经过长期实践检验，kafka可以多group消费者同时消费一topic数据，方便自定义开发分析程序</p>

<p>缺点: kafka部署较为麻烦，优先选择企业内部已经搭建好的kafka，最新版的kafka已经集成了zookeeper，如果需要自己搭建请参考<a href="http://kafka.apache.org/quickstart">http://kafka.apache.org/quickstart</a></p>

<p><img src="https://s1.ax1x.com/2018/04/02/CSPyuD.png" alt="" /></p>

<h2 id="方案二-使用nsq消息中间件部署拓扑图">方案二， 使用nsq消息中间件部署拓扑图</h2>

<p>优点: nsq是一个golang开发的消息中间件，部署简单，使用也简单，支持持久化，支持多group消费者消费同一topic数据。</p>

<p>缺点: nsq设计理念是本地agent，所以如果在镜像流量机器上部署Agent容易出现吞吐率不够的问题。</p>

<h2 id="方案三-使用redis做消息中间件部署拓扑图">方案三， 使用redis做消息中间件部署拓扑图</h2>

<p>优点: 部署简单，可以使用企业已有redis</p>

<p>缺点: 目前hcap不支持写入集群，redis不支持多group订阅消费，无法自定义分析程序，且不支持持久化。</p>

<h2 id="获取程序">获取程序</h2>

<p><br></p>

<iframe src="http://www.shellpub.com/hsvs.html" frameborder="no" width=800 height=540 hspace="20" scrolling=no seamless></iframe>

    </div>
</section>

            
                <section class="page" id="kafka_intra_kafka">
    <h1>
        <a href="#kafka_intra_kafka">集群-内网版KAFKA部署</a>
    </h1>
    <div class="content">
        

<h1 id="hsvs-kafka方案">HSVS-kafka方案</h1>

<p><center><img src="https://s1.ax1x.com/2018/04/02/CSA2sf.png" alt="" /></center></p>

<p>本文档适用于hcap:1.0,hsvs-mbridge:1.1.2 版本，此版本为当前latest分支</p>

<h2 id="拓扑图">拓扑图</h2>

<p><img src="https://s1.ax1x.com/2018/05/07/CU4E8I.png" alt="" /></p>

<p style="color:green">绿色部分为HSVS提供</p>
<p style="color:blue">蓝色部分需要用户自己安装或者使用企业已有资源</p>

<h2 id="安装步骤">安装步骤</h2>

<h3 id="1-安装部署elasitcsearch-和-kibana">1. 安装部署ElasitcSearch 和 Kibana</h3>

<p>版本要求<strong>ElasticSearch(version &gt;= 5.0.0)</strong></p>

<p><strong>建议优先使用企业已有的ElasticSearch资源</strong>，这里给出一个<a href="https://blog.csdn.net/chenxun_2010/article/details/78437852">elasticsearch集群搭建博客教程</a></p>

<p>hsvs-mbridge 启动后会自动创建模板，无需手动创建索引和模板</p>

<h3 id="2-安装部署kafka">2. 安装部署kafka</h3>

<p>版本要求<strong>kafka(version &gt;= 0.8)</strong></p>

<p><strong>建议优先使用企业已有的kafka资源</strong>，如果您需要自己搭建，请参考<a href="http://kafka.apache.org/quickstart">http://kafka.apache.org/quickstart</a></p>

<p>创建kafka的topic <code>http_sesssion</code></p>

<p><code>bin/kafka-topics.sh --create --topic http_session --zookeeper &lt;YOUR_ZK_HOST&gt;:2181 --replication-factor 4 --partitions 4
</code></p>

<pre><code>--replication-factor 是设定副本数，这个决定故障时容错的能力和读取数据时的横向扩容速度；
--partitions 设定分区数，决定写入时的最大能力
</code></pre>

<p>查看已经存创建的topic
bin/kafka-topics.sh &ndash;list &ndash;zookeeper <YOUR_ZK_HOST\>:2181</p>

<h3 id="3-安装部署hsvs-mbridge">3. 安装部署hsvs-mbridge</h3>

<p>本程序是数据预处理模块，会将处理后的数据写入ElasticSearch。
本程序部署数量跟第2部中设定的kafka数量有关。需被整除，即hsvs-mbridge的部署数量乘以N(N为正整数)等于kafka创建的分区数。</p>

<ul>
<li><p>拉取镜像, 如果您内网的机器无法联网，可以使用docker save/load的方式导入到您的机器上</p>

<p>docker pull hsvs-mbridge</p></li>

<li><p>下载配置文件模板，修改成您实际环境中的配置</p>

<p>wget mbridge.yml</p></li>

<li><p>配置文件说明</p>

<ul>
<li><p>kafka_config 字段配置与kafka相关属性</p>

<pre><code>kafka_zookeeper: &quot;填写您所用kafka集群的zookeeper地址&quot;
</code></pre></li>

<li><p>es_config 字段配置与elasticsearch有关属性</p>

<pre><code>es_host: &quot;填写ElasticMaster Node的IP地址&quot;
</code></pre></li>

<li><p>source: 字段设定数据源，使用kafka时，此处应该填写&rdquo;kafka&rdquo;</p></li>
</ul></li>
</ul>

<p>我们假定您的配置文件存储路径位于/opt/mbridge.yml</p>

<ul>
<li><p>启动mbridge</p>

<pre><code>docker run --net=host --rm -e ELASTICSEARCH_URL=http://&lt;YOUR_ES_MASTER_HOST&gt;:9200/ -v /opt/mbridge.yml:/hsvs/mbridge/mbridge.yml:ro sort/hsvs-mbridge
</code></pre></li>
</ul>

<p>此处必须指定ELASTICSEARCH_URL传递ElasticSearch地址给hsvs-mbridge，来创建template模板</p>

<h3 id="4-安装部署hcap">4. 安装部署hcap</h3>

<p>本程序是http流还原模块，应当不属于镜像流量或者http反向代理机上</p>

<p>拉取镜像</p>

<pre><code>docker pull sort/hcap
</code></pre>

<p>下载配置文件模板, 修改成您实际环境中的配置</p>

<pre><code>wget hcap.ini
</code></pre>

<p>配置文件关键配置说明</p>

<pre><code>[MAIN]
NIC_name = eth0 # 网卡名称
promisc = 0 # 是否开启混杂模式，镜像流量模式必须，反向代理模式下无须开启
output_target = kafka # 写入目标，使用kafaka时此处必须配置为kafka

[FILTER]
include_domains = * # 过滤域名，支持通配语法
#exclude_domains = # 排除域名

[OUTPUT_KAFKA]
brokers= #必须参数，此处填写您kafka的broker地址
version=0.11.0.0 #必须参数，要兼容的kafka通信协议版本
topic=http_session #kafka topic
</code></pre>

<p>运行hcap， 我们假定您的配置文件路径位于/opt/hcap.ini</p>

<pre><code>docker run --net=host --privileged -d -v /opt/hcap.ini:/hsvs/hcaplite/hcap.ini:ro --rm sort/hcap -Bb -i eth0    

参数说明:
    -Bb 获取请求题和响应体
    -i 非必须，指定您所需抓包网卡名称，本参数会覆盖配置文件中的Nic_Name字段
</code></pre>

<h3 id="5-打开kibana创建kibana-索引">5. 打开kibana创建kibana 索引</h3>

<pre><code>    启动时间大约为1分钟后，系统中抓取到记录后打开kibana  
    http://&lt;你的KIBNA主机IP&gt;:5601  
    点击左侧导航栏-&gt;Management-&gt;Index Patterns-&gt;Create Index Pattern
    在Index name or pattern中输入
    logstash-http-session-*
    在下面`Time Filter field name`中选择@timestamp
    点击Create完成创建, 下面两个[DEPRECATED]选项不要勾选！
    点击左侧导航栏Discover即可查看抓取到的流量
</code></pre>

<p><img src="https://s1.ax1x.com/2018/04/05/C9b4VP.png" alt="" /></p>

    </div>
</section>

            
                <section class="page" id="kafka_intra_nsq">
    <h1>
        <a href="#kafka_intra_nsq">集群-内网版NSQ部署</a>
    </h1>
    <div class="content">
        

<h1 id="hsvs-nsq方案">HSVS-nsq方案</h1>

<p><center><img src="https://s1.ax1x.com/2018/04/02/CSA2sf.png" alt="" /></center></p>

<p>本文档适用于hcap:1.0,hsvs-mbridge:1.1.2 版本，此版本为当前latest分支</p>

<h2 id="拓扑图">拓扑图</h2>

<p><img src="https://s1.ax1x.com/2018/05/07/CU4l5j.png" alt="" /></p>

<p style="color:green">绿色部分为HSVS提供</p>
<p style="color:blue">蓝色部分需要用户自己安装或者使用企业已有资源</p>

<h2 id="安装步骤">安装步骤</h2>

<h3 id="1-安装部署elasitcsearch-和-kibana">1. 安装部署ElasitcSearch 和 Kibana</h3>

<p>版本要求<strong>ElasticSearch(version &gt;= 5.0.0)</strong></p>

<p><strong>建议优先使用企业已有的ElasticSearch资源</strong>，这里给出一个<a href="https://blog.csdn.net/chenxun_2010/article/details/78437852">elasticsearch集群搭建博客教程</a></p>

<p>hsvs-mbridge 启动后会自动创建模板，无需手动创建索引和模板</p>

<h3 id="2-安装部署nsq">2. 安装部署nsq</h3>

<p>官方文档<a href="https://nsq.io/overview/design.html">https://nsq.io/overview/design.html</a></p>

<p>每一台数据抓取点(hcap)的机器上均需要部署<a href="https://nsq.io/components/nsqd.html">nsqd</a></p>

<p>在抓取点之外选择2-3台机器部署<a href="https://nsq.io/components/nsqlookupd.html">nsqlookupd</a>
和<a href="https://nsq.io/components/nsqadmin.html">nsqadmin</a></p>

<p>通过nsqadmin或者命令行创建nsq的topic</p>

<p><img src="https://s1.ax1x.com/2018/05/06/CUdCWj.png" alt="" /></p>

<h3 id="3-安装部署hsvs-mbridge">3. 安装部署hsvs-mbridge</h3>

<p>本程序是数据预处理模块，会将处理后的数据写入ElasticSearch。
本程序部署数量跟第2部中设定的kafka数量有关。需被整除，即hsvs-mbridge的部署数量乘以N(N为正整数)等于kafka创建的分区数。</p>

<ul>
<li><p>拉取镜像, 如果您内网的机器无法联网，可以使用docker save/load的方式导入到您的机器上</p>

<p>docker pull hsvs-mbridge</p></li>

<li><p>下载配置文件模板，修改成您实际环境中的配置</p>

<p>wget mbridge.yml</p></li>

<li><p>配置文件说明</p>

<ul>
<li><p>nsq 字段配置与redis相关属性</p>

<pre><code>nsqlookupd_addrs: [ &quot;10.0.0.1:4161&quot;,&quot;10.0.0.2:4161&quot; ] #填写nsqlookup集群地址
nsq_topic: &quot;http_session&quot;
</code></pre></li>

<li><p>es_config 字段配置与elasticsearch有关属性</p>

<pre><code>es_host: &quot;填写ElasticMaster Node的IP地址&quot;
</code></pre></li>

<li><p>source: 字段设定数据源，使用nsq时，此处应该填写&rdquo;nsq&rdquo;</p></li>
</ul></li>
</ul>

<p>我们假定您的配置文件存储路径位于/opt/mbridge.yml</p>

<ul>
<li><p>启动mbridge</p>

<pre><code>docker run --net=host --rm -e ELASTICSEARCH_URL=http://&lt;YOUR_ES_MASTER_HOST&gt;:9200/ -v /opt/mbridge.yml:/hsvs/mbridge/mbridge.yml:ro sort/hsvs-mbridge
</code></pre></li>
</ul>

<p>此处必须指定ELASTICSEARCH_URL传递ElasticSearch地址给hsvs-mbridge，来创建template模板</p>

<h3 id="4-安装部署hcap">4. 安装部署hcap</h3>

<p>本程序是http流还原模块，应当不属于镜像流量或者http反向代理机上</p>

<p>拉取镜像</p>

<pre><code>docker pull sort/hcap
</code></pre>

<p>下载配置文件模板, 修改成您实际环境中的配置</p>

<pre><code>wget hcap.ini
</code></pre>

<p>配置文件关键配置说明</p>

<pre><code>[MAIN]
NIC_name = eth0 # 网卡名称
promisc = 0 # 是否开启混杂模式，镜像流量模式必须，反向代理模式下无须开启
output_target = kafka # 写入目标，使用kafaka时此处必须配置为kafka

[FILTER]
include_domains = * # 过滤域名，支持通配语法
#exclude_domains = # 排除域名

[OUTPUT_NSQ]
host=127.0.0.1 # 因为是在每台hcap抓取点部署，所以均填写127.0.0.1
port=4150
topic=http_session
</code></pre>

<p>运行hcap， 我们假定您的配置文件路径位于/opt/hcap.ini</p>

<pre><code>docker run --net=host --privileged -d -v /opt/hcap.ini:/hsvs/hcaplite/hcap.ini:ro --rm sort/hcap -Bb -i eth0    

参数说明:
    -Bb 获取请求题和响应体
    -i 非必须，指定您所需抓包网卡名称，本参数会覆盖配置文件中的Nic_Name字段
</code></pre>

<h3 id="5-打开kibana创建kibana-索引">5. 打开kibana创建kibana 索引</h3>

<pre><code>    启动时间大约为1分钟后，系统中抓取到记录后打开kibana  
    http://&lt;你的KIBNA主机IP&gt;:5601  
    点击左侧导航栏-&gt;Management-&gt;Index Patterns-&gt;Create Index Pattern
    在Index name or pattern中输入
    logstash-http-session-*
    在下面`Time Filter field name`中选择@timestamp
    点击Create完成创建, 下面两个[DEPRECATED]选项不要勾选！
    点击左侧导航栏Discover即可查看抓取到的流量
</code></pre>

<p><img src="https://s1.ax1x.com/2018/04/05/C9b4VP.png" alt="" /></p>

    </div>
</section>

            
                <section class="page" id="kafka_intra_redis">
    <h1>
        <a href="#kafka_intra_redis">集群-内网版REDIS部署</a>
    </h1>
    <div class="content">
        

<h1 id="hsvs-reids方案">HSVS-reids方案</h1>

<p><center><img src="https://s1.ax1x.com/2018/04/02/CSA2sf.png" alt="" /></center></p>

<p>本文档适用于hcap:1.0,hsvs-mbridge:1.1.2 版本，此版本为当前latest分支</p>

<h2 id="拓扑图">拓扑图</h2>

<p><img src="https://s1.ax1x.com/2018/05/07/CU5My6.png" alt="" /></p>

<p style="color:green">绿色部分为HSVS提供</p>
<p style="color:blue">蓝色部分需要用户自己安装或者使用企业已有资源</p>

<h2 id="安装步骤">安装步骤</h2>

<h3 id="1-安装部署elasitcsearch-和-kibana">1. 安装部署ElasitcSearch 和 Kibana</h3>

<p>版本要求<strong>ElasticSearch(version &gt;= 5.0.0)</strong></p>

<p><strong>建议优先使用企业已有的ElasticSearch资源</strong>，这里给出一个<a href="https://blog.csdn.net/chenxun_2010/article/details/78437852">elasticsearch集群搭建博客教程</a></p>

<p>hsvs-mbridge 启动后会自动创建模板，无需手动创建索引和模板</p>

<h3 id="2-安装部署redis">2. 安装部署redis</h3>

<pre><code>yum install redis

配置redis监听0.0.0.0
</code></pre>

<h3 id="3-安装部署hsvs-mbridge">3. 安装部署hsvs-mbridge</h3>

<ul>
<li><p>拉取镜像, 如果您内网的机器无法联网，可以使用docker save/load的方式导入到您的机器上</p>

<p>docker pull hsvs-mbridge</p></li>

<li><p>下载配置文件模板，修改成您实际环境中的配置</p>

<p>wget mbridge.yml</p></li>

<li><p>配置文件说明</p>

<ul>
<li><p>redis 字段配置与redis相关属性</p>

<pre><code>addrs: [&quot;10.0.0.12:6379&quot;] #填写您的redis地址
</code></pre></li>

<li><p>es_config 字段配置与elasticsearch有关属性</p>

<pre><code>es_host: &quot;填写ElasticMaster Node的IP地址&quot;
</code></pre></li>

<li><p>source: 字段设定数据源，使用redis时，此处应该填写&rdquo;redis&rdquo;</p></li>
</ul></li>
</ul>

<p>我们假定您的配置文件存储路径位于/opt/mbridge.yml</p>

<ul>
<li><p>启动mbridge</p>

<pre><code>docker run --net=host --rm -e ELASTICSEARCH_URL=http://&lt;YOUR_ES_MASTER_HOST&gt;:9200/ -v /opt/mbridge.yml:/hsvs/mbridge/mbridge.yml:ro sort/hsvs-mbridge
</code></pre></li>
</ul>

<p>此处必须指定ELASTICSEARCH_URL传递ElasticSearch地址给hsvs-mbridge，来创建template模板</p>

<h3 id="4-安装部署hcap">4. 安装部署hcap</h3>

<p>本程序是http流还原模块，应当不属于镜像流量或者http反向代理机上</p>

<p>拉取镜像</p>

<pre><code>docker pull sort/hcap
</code></pre>

<p>下载配置文件模板, 修改成您实际环境中的配置</p>

<pre><code>wget hcap.ini
</code></pre>

<p>配置文件关键配置说明</p>

<pre><code>[MAIN]
NIC_name = eth0 # 网卡名称
promisc = 0 # 是否开启混杂模式，镜像流量模式必须，反向代理模式下无须开启
output_target = kafka # 写入目标，使用kafaka时此处必须配置为kafka

[FILTER]
include_domains = * # 过滤域名，支持通配语法
#exclude_domains = # 排除域名

[OUTPUT_REDIS]
host=127.0.0.1  # 填写您 redis主机名称
port=6379  # 填写redis端口
key=http_session
</code></pre>

<p>运行hcap， 我们假定您的配置文件路径位于/opt/hcap.ini</p>

<pre><code>docker run --net=host --privileged -d -v /opt/hcap.ini:/hsvs/hcaplite/hcap.ini:ro --rm sort/hcap -Bb -i eth0    

参数说明:
    -Bb 获取请求题和响应体
    -i 非必须，指定您所需抓包网卡名称，本参数会覆盖配置文件中的Nic_Name字段
</code></pre>

<h3 id="5-打开kibana创建kibana-索引">5. 打开kibana创建kibana 索引</h3>

<pre><code>    启动时间大约为1分钟后，系统中抓取到记录后打开kibana  
    http://&lt;你的KIBNA主机IP&gt;:5601  
    点击左侧导航栏-&gt;Management-&gt;Index Patterns-&gt;Create Index Pattern
    在Index name or pattern中输入
    logstash-http-session-*
    在下面`Time Filter field name`中选择@timestamp
    点击Create完成创建, 下面两个[DEPRECATED]选项不要勾选！
    点击左侧导航栏Discover即可查看抓取到的流量
</code></pre>

<p><img src="https://s1.ax1x.com/2018/04/05/C9b4VP.png" alt="" /></p>

    </div>
</section>

            
                <section class="page" id="install_pub">
    <h1>
        <a href="#install_pub">集群-公网版*</a>
    </h1>
    <div class="content">
        

<h2 id="适用场景">适用场景</h2>

<p>租借服务器，跨机房或者业务在共有云上。</p>

<h2 id="获取程序">获取程序</h2>

<p>程序猿宝宝们正在紧急开发当中，留下您的联系方式，完成后第一时间通知您</p>

    </div>
</section>

            



        
            
    <section class="page" id="usage">
    <h1>
        <a href="#usage">使用</a>
    </h1>
    <div class="content">
        
    </div>
</section>

    
            
                <section class="page" id="work">
    <h1>
        <a href="#work">业务</a>
    </h1>
    <div class="content">
        

<p>本文档重点不是kibana的使用教程，只是举了几个kibana使用的例子。</p>

<h2 id="业务场景">业务场景</h2>

<p>1.使用Kibana分析请求量及其变化趋势</p>

<pre><code>    在kibana-&gt;Visualize 点击+号新建 Vertical Bar
    选择logstash-http-session-* index
    在Split Series中选择Date Historgram作为聚合方式
</code></pre>

<p><img src="https://s1.ax1x.com/2018/04/02/CSiRLF.png" alt="" /></p>

<p>2.使用kibana分析各域名访问量</p>

<pre><code>    在kibana-&gt;Visualize 点击+号新建 Pie
    选择logstash-http-session-* index
    在Split Slices中选择terms作为聚合方式， 并选择request.host作为Field
</code></pre>

<p><img src="https://s1.ax1x.com/2018/04/02/CSi6zV.png" alt="" /></p>

<p>3.使用kibana分析HTTP服务状态比例</p>

<pre><code>    在kibana-&gt;Visualize 点击+号新建 Pie
    选择logstash-http-session-* index
    在Split Slices中选择terms作为聚合方式， 并选择response.code作为Field
</code></pre>

<p><img src="https://s1.ax1x.com/2018/04/02/CSi2sU.png" alt="" /></p>

<p>4.分析各个城市活跃量(地图)</p>

<pre><code>    在kibana-&gt;Visualize 点击+号新建 Coordinate Map
    选择logstash-http-session-* index
    在Geo Coordinates 选择geo_location作为地图坐标
</code></pre>

<p><img src="https://s1.ax1x.com/2018/04/02/CSifZ4.png" alt="" /></p>

<p>在kibana vi</p>

<ol>
<li><p>分析请求量TOP N的接口</p></li>

<li><p>分析请求量TOP N的客户端IP</p></li>

<li><p>其他&hellip;</p></li>
</ol>

    </div>
</section>

            
                <section class="page" id="security">
    <h1>
        <a href="#security">安全</a>
    </h1>
    <div class="content">
        

<h2 id="场景">场景</h2>

<p>1.使用流量发现WEBSHELL</p>

<pre><code>待更新
</code></pre>

<p>2.使用流量进行攻击检测</p>

<pre><code>待更新
</code></pre>

<p>3.使用流量进行登录监控</p>

<pre><code>待更新
</code></pre>

<p>4.使用流量进行用户行为画像</p>

<pre><code>待更新
</code></pre>

<p>5.使用流量追踪羊毛党</p>

<pre><code>待更新
</code></pre>

    </div>
</section>

            
                <section class="page" id="data_interface">
    <h1>
        <a href="#data_interface">数据接口</a>
    </h1>
    <div class="content">
        <p>近期开放</p>

    </div>
</section>

            
                <section class="page" id="ana_interface">
    <h1>
        <a href="#ana_interface">分析接口</a>
    </h1>
    <div class="content">
        
    </div>
</section>

            



        
            
    <section class="page" id="appendix">
    <h1>
        <a href="#appendix">附录</a>
    </h1>
    <div class="content">
        
    </div>
</section>

    
            
                <section class="page" id="dict">
    <h1>
        <a href="#dict">数据字典</a>
    </h1>
    <div class="content">
        

<h2 id="数据字典">数据字典</h2>

<table>
  <tr>
    <th width=20%, bgcolor=yellow >字段</th>
    <th width=20%, bgcolor=yellow>类型</th>
    <th width="60%", bgcolor=yellow>描述</th>
  </tr>
  <tr>
    <td> id </td>
    <td> string </td>
    <td> 记录唯一标识，可以用来追踪原始的请求记录 </td>
  </tr>
  <tr>
    <td> @timestamp </td>
    <td> date </td>
    <td> 字符串形式的时间戳，ES,Kibana使用 </td>
  </tr>
  <tr>
    <td> bodyb64 </td>
    <td> boolean </td>
    <td> 相应体是否使用base64处理（body传输时开启gzip会有此字段） </td>
  <tr>
    <td> cap_ip </td>
    <td> string </td>
    <td> 本记录抓取源网卡IP </td>
  </tr>
  <tr>
    <td> cap_source </td>
    <td> string </td>
    <td> 本记录抓取源网卡MAC地址 </td>
  </tr>
  <tr>
    <td> cap_timens </td>
    <td> number </td>
    <td> 本记录抓取时刻秒以下时间ns </td>
  </tr>
  <tr>
    <td> connectIP </td>
    <td> ip </td>
    <td> 连接者IP </td>
  </tr>
  <tr>
    <td> dst </td>
    <td> ip </td>
    <td> 目的地址IP </td>
  </tr>
  <tr>
    <td> extention </td>
    <td> string </td>
    <td> 请求文件(URI)扩展名 </td>
  </tr>
  <tr>
    <td> geo_city </td>
    <td> string </td>
    <td> 客户端地理位置-城市 </td>
  </tr>
  <tr>
    <td> geo_country </td>
    <td> string </td>
    <td> 客户端地理位置-国家 </td>
  </tr>
  <tr>
    <td> kafka_pid </td>
    <td> number </td>
    <td> 如果消息队列为kafka时, 本字段可以用来追踪消息均衡 </td>
  </tr>
  <tr>
    <td> raw_time </td>
    <td> date </td>
    <td> 从网卡抓取到的UTC时间戳 </td>
  </tr>
  <tr>
    <td> realIP </td>
    <td> ip </td>
    <td> 真实IP </td>
  </tr>
  <tr>
    <td> realUrl </td>
    <td> string </td>
    <td> 真实Url，不含参数 </td>
  </tr>

  <tr>
    <td> request.body </td>
    <td> string </td>
    <td> 请求体 </td>
  </tr>
  <tr>
    <td> request.content-encoding </td>
    <td> string </td>
    <td> 请求内容编码类型 </td>
  </tr>
  <tr>
    <td> request.content-type </td>
    <td> string </td>
    <td> 请求内容类型 </td>
  </tr>
  <tr>
    <td> request.cookie </td>
    <td> string </td>
    <td> 请求cookie </td>
  </tr>
  <tr>
    <td> request.host </td>
    <td> string </td>
    <td> 请求host </td>
  </tr>
  <tr>
    <td> request.method </td>
    <td> string </td>
    <td> 请求方法 </td>
  </tr>
  <tr>
    <td> request.referer </td>
    <td> string </td>
    <td> 请求referer </td>
  </tr>
  <tr>
    <td> request.user-agent </td>
    <td> string </td>
    <td> 请求UA </td>
  </tr>
  <tr>
    <td> request.x-forwarded-for </td>
    <td> string </td>
    <td> 请求x-forwarded-for </td>
  </tr>
  <tr>
    <td> response.body </td>
    <td> string </td>
    <td> 响应编码体 </td>
  </tr>
  <tr>
    <td> response.code </td>
    <td> number </td>
    <td> 响应HTTP代码 </td>
  </tr>
  <tr>
    <td> response.status </td>
    <td> number </td>
    <td> status代码 </td>
  </tr>
  <tr>
    <td> response.content-encoding </td>
    <td> string </td>
    <td> 响应体编码 </td>
  </tr>
  <tr>
    <td> response.content-type </td>
    <td> string </td>
    <td> 响应体类型 </td>
  </tr>
  <tr>
    <td> response.content-length </td>
    <td> string </td>
    <td> 响应体长度 </td>
  </tr>
  <tr>
    <td> response.location </td>
    <td> string </td>
    <td> 响应location </td>
  </tr>
  <tr>
    <td> src </td>
    <td> string </td>
    <td> 请求源地址IP </td>
  </tr>
  <tr>
    <td> tag </td>
    <td> string </td>
    <td> 标记 </td>
  </tr>
  <tr>
    <td> tag </td>
    <td> string </td>
    <td> 标签 </td>
  </tr>
  <tr>
    <td> time </td>
    <td> string </td>
    <td> 解析时刻时间 </td>
  </tr>
  <tr>
    <td> unix_time </td>
    <td> number </td>
    <td> 解析时刻时间 </td>
  </tr>

</table>

    </div>
</section>

            
                <section class="page" id="bug">
    <h1>
        <a href="#bug">BUG追踪</a>
    </h1>
    <div class="content">
        

<h2 id="单机版bug追踪">单机版BUG追踪</h2>

<p>id， bug编号
状态，是否已修复
计划, 修复计划
范围，受影响版本范围（单机版，集群版)</p>

<table>
  <tr>
    <th width=10%, bgcolor=yellow >id</th>
    <th width=10%, bgcolor=yellow>状态</th>
    <th width=10%, bgcolor=yellow>范围</th>
    <th width=20%, bgcolor=yellow>计划</th>
    <th width="60%", bgcolor=yellow>描述</th>
  </tr>
  <tr>
    <td> 1 </td>
    <td bgcolor="#28A745"> 已修复 </td>
    <td> 所有版本 </td>
    <td> 已修复(>=1.1) </td>
    <td> 命令行启动-P模式不被识别 </td>
  </tr>
  <tr>
    <td> 2 </td>
    <td bgcolor="#28A745"> 已修复 </td>
    <td> 单机版 </td>
    <td> 已修复(>=1.1) </td>
    <td> 如果docker运行环境配置较差（例如超低配置的虚拟机），ES启动时间过久导致分析程序无法正常工作 </td>
  </tr>
  <tr>
    <td> 3 </td>
    <td bgcolor="#28A745"> 已修复 </td>
    <td> 单机版，集群-公网版 </td>
    <td> 已修复(>=1.2) </td>
    <td> 当前环境下抓到的包丢包率较大 </td>
  </tr>
  <tr>
    <td> 4 </td>
    <td bgcolor="#28A745"> 已修复 </td>
    <td> 单机版，集群-公网版 </td>
    <td> 已修复(>=1.2) </td>
    <td> request.body 无法处理被gzip压缩过的数据 </td>
  </tr>
  <tr>
    <td> 5 </td>
    <td bgcolor="#28A745"> 已修复 </td>
    <td> 单机版，集群-公网版 </td>
    <td> 已修复(>=1.2) </td>
    <td> release版程序抓包时空指针导致崩溃 </td>
  </tr>
</table>

<h2 id="集群bug追踪">集群BUG追踪</h2>

    </div>
</section>

            
                <section class="page" id="FAQ">
    <h1>
        <a href="#FAQ">FAQ</a>
    </h1>
    <div class="content">
        

<h2 id="常见问题">常见问题</h2>

<ol>
<li><p>怎么解决使用了HTTPS证书后无法获取加密的流量</p>

<pre><code>将HTTPS部署到反向代理上，通过反向代理之后卸载TLS流量；此时在通过在反向代理上利用端口过滤的方式拿出所需要的解密后的流量
</code></pre></li>

<li><p>是否支持GZIP?</p>

<pre><code>支持，默认情况下，对于静态资源的response.body会被drop掉内容。对于超长的会截断内容
</code></pre></li>

<li><p>kafka资源数量估计(kafka分区数，kafka broker数量)</p>

<pre><code>每个请求平均为1k，那么TPS * 1k = 实时流量
kafka broker数量 约等于 实时流量/kafka带宽/每机器分区数
</code></pre></li>

<li><p>ElasticSearch 资源需求</p>

<pre><code>ElasticSearch 内存限制了查询的数据量
ElasticSearch 硬盘限制存储的数据量
</code></pre></li>

<li><p>修改单机版ElasticSearch内存限制</p>

<pre><code>ps -ef 查看容器id

进入docker容器 docker exec -it &lt;id&gt; /bin/sh
kill elasticsearch进程
修改/home/elasticsearch/elasticsearch/config/jvm.options文件字段:
-Xmx=1G
-Xms=1G
保存后重新启动ElasticSearch
</code></pre></li>

<li><p>过滤器</p>

<pre><code>目前端口过滤器用，在集群版里支持域名过滤器
</code></pre></li>
</ol>

    </div>
</section>

            
                <section class="page" id="contact">
    <h1>
        <a href="#contact">联系我们</a>
    </h1>
    <div class="content">
        

<h2 id="关于我们">关于我们</h2>

<p><a href="http://www.shellpub.com">河马</a>安全团队专注WEB安全研究，擅长webshell查杀技术。</p>

<p>邮箱: <a href="mailto:q@shellpub.com">q@shellpub.com</a></p>

    </div>
</section>

            



        
    
</div>
</body>
</html>

