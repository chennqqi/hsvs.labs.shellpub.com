<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HSVS-HTTP全流量可视化系统</title>
    <link>/</link>
    <description>Recent content on HSVS-HTTP全流量可视化系统</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 02 Apr 2018 21:48:10 +0800</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>功能特点</title>
      <link>/%E7%AE%80%E4%BB%8B/1/</link>
      <pubDate>Mon, 02 Apr 2018 21:48:10 +0800</pubDate>
      
      <guid>/%E7%AE%80%E4%BB%8B/1/</guid>
      <description>特性  一键部署 开箱即用 分析接口开放 数据接口开放 地理位置解析 真实IP提取 智能状态码、UID、手机号 支持流量镜像  项目结构 抓取模块
消息队列
基础分析程序
ES+kibna 分析展示模块</description>
    </item>
    
    <item>
      <title>单机版</title>
      <link>/%E5%AE%89%E8%A3%85/standalone/</link>
      <pubDate>Mon, 02 Apr 2018 21:48:10 +0800</pubDate>
      
      <guid>/%E5%AE%89%E8%A3%85/standalone/</guid>
      <description>适用场景 业务量较小的网站或者公司，完整集成包，开箱即用。
需求  空闲内存&amp;gt;1.5GB (内置ES内存限制为1G， 如果内存较大可以手动修改，配置不要超过系统内存的一半) tps &amp;lt; 3000 cpu核心数&amp;gt;=2  部署方式 1.流量镜像模式；
2.直接在反向代理部署, 确保你的反向代理开启了X_FORWARD_FOF；
3.如果使用了HTTPS，可以结合1，2两种方案进行, 在反向代理抓取HTTPS卸载之后的流量，在镜像抓取纯HTTP流量
依赖  docker  获取程序 官方源:
docker pull sort/hsvs-standalone  docker官方中国源(推荐):
docker pull registry.docker-cn.com/sort/hsvs-standalone  运行说明  首先应当在您的环境下安装Docker
 拉取镜像
docker pull sort/hsvs-standalone
 运行
  docker run -d --privileged=true --net=host -p 5601:5601 -p 9200:9200 sort/hsvs-standalone -f &amp;#39;tcp port 80&amp;#39; -i eth0 -P docker参数说明 -d 让docker镜像以后台守护进程的方式运行 -p docker 端口，将docker内部的kibana 和elasticsearch端口映射到主机 --privilged=true 开启root权限，允许docker程序抓包 --net=host 使用主机网络，这样docker里程序可以抓取主机流量 运行参数说明 -i &amp;lt;ethname&amp;gt; 指定网卡名称 -f &amp;lt;port filter&amp;gt; 可选， 指定过滤端口信息， 如果不加此选项默认会处理所有端口， 这个选项在https反代抓包时很有用，过滤器语法同tcpdump语法 -P 可选，开启混杂模式，在流量镜像模式抓包时使用，  4.</description>
    </item>
    
    <item>
      <title>集群-内网版*</title>
      <link>/%E5%AE%89%E8%A3%85/cluster_intra/</link>
      <pubDate>Sun, 28 Jan 2018 21:48:10 +0100</pubDate>
      
      <guid>/%E5%AE%89%E8%A3%85/cluster_intra/</guid>
      <description> 适用场景 企业内网，IDC机房。 可以采用两种部署模式：
1. 流量镜像模式；
2. 直接在反向代理部署；
3. 如果使用了HTTPS，可以结合1，2两种方案进行
依赖  docker elasticsearch(建议版本&amp;gt;=5.0) kibana(建议版本&amp;gt;=5.0) 消息队列(推荐kafka, 如无可以使用redis/nsq替代) elasticsearch XPack插件(可选)  环境要求  镜像流量建议单独部署到物理机（根据实际情况内存需求&amp;gt;tps*3000 Byte)，如果流量过大需要使用网络分流器 消息中间件kafka (可选nsq和redis) ElasticSearch 集群  节点描述  hcap 抓取模块，负责将http流还原成json数据 消息中间件(kafka/nsq/redis) mbridge，负责将json数据从消息中间件中处理写入ElasticSearch ElasticSearch + kibana 最终的消息存储和可视化的显示 analyzed(尚未开发完成) 负责实时分析流量，根据配置的（安全或者风控）规则出处命中结果到ElasticSearch  方案一(强烈建议), 使用kafka消息中间件部署拓扑图 优点: kafka吞吐率，稳定性，持久化很优秀，经过长期实践检验，kafka可以多group消费者同时消费一topic数据，方便自定义开发分析程序
缺点: kafka部署较为麻烦，优先选择企业内部已经搭建好的kafka，最新版的kafka已经集成了zookeeper，如果需要自己搭建请参考http://kafka.apache.org/quickstart
方案二， 使用nsq消息中间件部署拓扑图 优点: nsq是一个golang开发的消息中间件，部署简单，使用也简单，支持持久化，支持多group消费者消费同一topic数据。
缺点: nsq设计理念是本地agent，所以如果在镜像流量机器上部署Agent容易出现吞吐率不够的问题。
方案三， 使用redis做消息中间件部署拓扑图 优点: 部署简单，可以使用企业已有redis
缺点: 目前hcap不支持写入集群，redis不支持多group订阅消费，无法自定义分析程序，且不支持持久化。
获取程序 
 </description>
    </item>
    
    <item>
      <title>集群-内网版KAFKA部署</title>
      <link>/%E5%AE%89%E8%A3%85/cluster_intra_kafka/</link>
      <pubDate>Mon, 07 May 2018 10:42:17 +0800</pubDate>
      
      <guid>/%E5%AE%89%E8%A3%85/cluster_intra_kafka/</guid>
      <description>HSVS-kafka方案 
本文档适用于hcap:1.0,hsvs-mbridge:1.1.2 版本，此版本为当前latest分支
拓扑图 绿色部分为HSVS提供
蓝色部分需要用户自己安装或者使用企业已有资源
安装步骤 1. 安装部署ElasitcSearch 和 Kibana 版本要求ElasticSearch(version &amp;gt;= 5.0.0)
建议优先使用企业已有的ElasticSearch资源，这里给出一个elasticsearch集群搭建博客教程
hsvs-mbridge 启动后会自动创建模板，无需手动创建索引和模板
2. 安装部署kafka 版本要求kafka(version &amp;gt;= 0.8)
建议优先使用企业已有的kafka资源，如果您需要自己搭建，请参考http://kafka.apache.org/quickstart
创建kafka的topic http_sesssion
bin/kafka-topics.sh --create --topic http_session --zookeeper &amp;lt;YOUR_ZK_HOST&amp;gt;:2181 --replication-factor 4 --partitions 4 
--replication-factor 是设定副本数，这个决定故障时容错的能力和读取数据时的横向扩容速度； --partitions 设定分区数，决定写入时的最大能力  查看已经存创建的topic bin/kafka-topics.sh &amp;ndash;list &amp;ndash;zookeeper :2181
3. 安装部署hsvs-mbridge 本程序是数据预处理模块，会将处理后的数据写入ElasticSearch。 本程序部署数量跟第2部中设定的kafka数量有关。需被整除，即hsvs-mbridge的部署数量乘以N(N为正整数)等于kafka创建的分区数。
 拉取镜像, 如果您内网的机器无法联网，可以使用docker save/load的方式导入到您的机器上
docker pull hsvs-mbridge
 下载配置文件模板，修改成您实际环境中的配置
wget mbridge.yml
 配置文件说明
 kafka_config 字段配置与kafka相关属性
kafka_zookeeper: &amp;quot;填写您所用kafka集群的zookeeper地址&amp;quot;  es_config 字段配置与elasticsearch有关属性</description>
    </item>
    
    <item>
      <title>更新历史</title>
      <link>/%E7%AE%80%E4%BB%8B/2/</link>
      <pubDate>Mon, 02 Apr 2018 21:48:10 +0800</pubDate>
      
      <guid>/%E7%AE%80%E4%BB%8B/2/</guid>
      <description>单机版更新历史  2018-04-03 单机版 2018-04-09 单机版 v1.1  修复-P混杂模式选项不能识别的BUG 修复IO过低时ElasticSearch程序启动过慢导致处理程序无法正常启动的BUG  2018-04-30 单机版 v1.2  增强request.body，支持gzip/zlib压缩数据 修正抓包程序没有正常返回输出描述符的BUG，该BUG导致release程序崩溃 使用gcc -O2方式编译hcaplite 调整模板 response.body request.body request.url request.x-forwarded-for request.user-agent 修改为text方式索引, 关于keyword和text的差异请参考https://www.elastic.co/guide/en/elasticsearch/reference/5.5/breaking_50_mapping_changes.html 初步解决了上一个版本存在严重丢包的问题   项目结构 抓取模块
消息队列
基础分析程序
ES+kibna 分析展示模块</description>
    </item>
    
    <item>
      <title>集群-内网版NSQ部署</title>
      <link>/%E5%AE%89%E8%A3%85/cluster_intra_nsq/</link>
      <pubDate>Mon, 07 May 2018 10:42:17 +0800</pubDate>
      
      <guid>/%E5%AE%89%E8%A3%85/cluster_intra_nsq/</guid>
      <description>HSVS-nsq方案 
本文档适用于hcap:1.0,hsvs-mbridge:1.1.2 版本，此版本为当前latest分支
拓扑图 绿色部分为HSVS提供
蓝色部分需要用户自己安装或者使用企业已有资源
安装步骤 1. 安装部署ElasitcSearch 和 Kibana 版本要求ElasticSearch(version &amp;gt;= 5.0.0)
建议优先使用企业已有的ElasticSearch资源，这里给出一个elasticsearch集群搭建博客教程
hsvs-mbridge 启动后会自动创建模板，无需手动创建索引和模板
2. 安装部署nsq 官方文档https://nsq.io/overview/design.html
每一台数据抓取点(hcap)的机器上均需要部署nsqd
在抓取点之外选择2-3台机器部署nsqlookupd 和nsqadmin
通过nsqadmin或者命令行创建nsq的topic
3. 安装部署hsvs-mbridge 本程序是数据预处理模块，会将处理后的数据写入ElasticSearch。 本程序部署数量跟第2部中设定的kafka数量有关。需被整除，即hsvs-mbridge的部署数量乘以N(N为正整数)等于kafka创建的分区数。
 拉取镜像, 如果您内网的机器无法联网，可以使用docker save/load的方式导入到您的机器上
docker pull hsvs-mbridge
 下载配置文件模板，修改成您实际环境中的配置
wget mbridge.yml
 配置文件说明
 nsq 字段配置与redis相关属性
nsqlookupd_addrs: [ &amp;quot;10.0.0.1:4161&amp;quot;,&amp;quot;10.0.0.2:4161&amp;quot; ] #填写nsqlookup集群地址 nsq_topic: &amp;quot;http_session&amp;quot;  es_config 字段配置与elasticsearch有关属性
es_host: &amp;quot;填写ElasticMaster Node的IP地址&amp;quot;  source: 字段设定数据源，使用nsq时，此处应该填写&amp;rdquo;nsq&amp;rdquo;
   我们假定您的配置文件存储路径位于/opt/mbridge.yml
 启动mbridge
docker run --net=host --rm -e ELASTICSEARCH_URL=http://&amp;lt;YOUR_ES_MASTER_HOST&amp;gt;:9200/ -v /opt/mbridge.</description>
    </item>
    
    <item>
      <title>集群-内网版REDIS部署</title>
      <link>/%E5%AE%89%E8%A3%85/cluster_intra_redis/</link>
      <pubDate>Mon, 07 May 2018 10:42:17 +0800</pubDate>
      
      <guid>/%E5%AE%89%E8%A3%85/cluster_intra_redis/</guid>
      <description>HSVS-reids方案 
本文档适用于hcap:1.0,hsvs-mbridge:1.1.2 版本，此版本为当前latest分支
拓扑图 绿色部分为HSVS提供
蓝色部分需要用户自己安装或者使用企业已有资源
安装步骤 1. 安装部署ElasitcSearch 和 Kibana 版本要求ElasticSearch(version &amp;gt;= 5.0.0)
建议优先使用企业已有的ElasticSearch资源，这里给出一个elasticsearch集群搭建博客教程
hsvs-mbridge 启动后会自动创建模板，无需手动创建索引和模板
2. 安装部署redis yum install redis 配置redis监听0.0.0.0  3. 安装部署hsvs-mbridge  拉取镜像, 如果您内网的机器无法联网，可以使用docker save/load的方式导入到您的机器上
docker pull hsvs-mbridge
 下载配置文件模板，修改成您实际环境中的配置
wget mbridge.yml
 配置文件说明
 redis 字段配置与redis相关属性
addrs: [&amp;quot;10.0.0.12:6379&amp;quot;] #填写您的redis地址  es_config 字段配置与elasticsearch有关属性
es_host: &amp;quot;填写ElasticMaster Node的IP地址&amp;quot;  source: 字段设定数据源，使用redis时，此处应该填写&amp;rdquo;redis&amp;rdquo;
   我们假定您的配置文件存储路径位于/opt/mbridge.yml
 启动mbridge
docker run --net=host --rm -e ELASTICSEARCH_URL=http://&amp;lt;YOUR_ES_MASTER_HOST&amp;gt;:9200/ -v /opt/mbridge.yml:/hsvs/mbridge/mbridge.yml:ro sort/hsvs-mbridge   此处必须指定ELASTICSEARCH_URL传递ElasticSearch地址给hsvs-mbridge，来创建template模板</description>
    </item>
    
    <item>
      <title>集群-公网版*</title>
      <link>/%E5%AE%89%E8%A3%85/cluster_pub/</link>
      <pubDate>Mon, 02 Apr 2018 21:48:10 +0800</pubDate>
      
      <guid>/%E5%AE%89%E8%A3%85/cluster_pub/</guid>
      <description>适用场景 租借服务器，跨机房或者业务在共有云上。
获取程序 程序猿宝宝们正在紧急开发当中，留下您的联系方式，完成后第一时间通知您</description>
    </item>
    
    <item>
      <title>数据字典</title>
      <link>/%E9%99%84%E5%BD%95/dict/</link>
      <pubDate>Mon, 02 Apr 2018 21:57:07 +0800</pubDate>
      
      <guid>/%E9%99%84%E5%BD%95/dict/</guid>
      <description>数据字典   字段 类型 描述    id   string   记录唯一标识，可以用来追踪原始的请求记录     @timestamp   date   字符串形式的时间戳，ES,Kibana使用     bodyb64   boolean   相应体是否使用base64处理（body传输时开启gzip会有此字段）    cap_ip   string   本记录抓取源网卡IP     cap_source   string   本记录抓取源网卡MAC地址     cap_timens   number   本记录抓取时刻秒以下时间ns     connectIP   ip   连接者IP     dst   ip   目的地址IP     extention   string   请求文件(URI)扩展名     geo_city   string   客户端地理位置-城市     geo_country   string   客户端地理位置-国家     kafka_pid   number   如果消息队列为kafka时, 本字段可以用来追踪消息均衡     raw_time   date   从网卡抓取到的UTC时间戳     realIP   ip   真实IP     realUrl   string   真实Url，不含参数     request.</description>
    </item>
    
    <item>
      <title>业务</title>
      <link>/%E7%94%A8%E6%B3%95/work/</link>
      <pubDate>Mon, 02 Apr 2018 21:55:52 +0800</pubDate>
      
      <guid>/%E7%94%A8%E6%B3%95/work/</guid>
      <description> 本文档重点不是kibana的使用教程，只是举了几个kibana使用的例子。
业务场景 1.使用Kibana分析请求量及其变化趋势
 在kibana-&amp;gt;Visualize 点击+号新建 Vertical Bar 选择logstash-http-session-* index 在Split Series中选择Date Historgram作为聚合方式  2.使用kibana分析各域名访问量
 在kibana-&amp;gt;Visualize 点击+号新建 Pie 选择logstash-http-session-* index 在Split Slices中选择terms作为聚合方式， 并选择request.host作为Field  3.使用kibana分析HTTP服务状态比例
 在kibana-&amp;gt;Visualize 点击+号新建 Pie 选择logstash-http-session-* index 在Split Slices中选择terms作为聚合方式， 并选择response.code作为Field  4.分析各个城市活跃量(地图)
 在kibana-&amp;gt;Visualize 点击+号新建 Coordinate Map 选择logstash-http-session-* index 在Geo Coordinates 选择geo_location作为地图坐标  在kibana vi
 分析请求量TOP N的接口
 分析请求量TOP N的客户端IP
 其他&amp;hellip;
  </description>
    </item>
    
    <item>
      <title>BUG追踪</title>
      <link>/%E9%99%84%E5%BD%95/bug/</link>
      <pubDate>Mon, 02 Apr 2018 21:57:07 +0800</pubDate>
      
      <guid>/%E9%99%84%E5%BD%95/bug/</guid>
      <description>单机版BUG追踪 id， bug编号 状态，是否已修复 计划, 修复计划 范围，受影响版本范围（单机版，集群版)
  id 状态 范围 计划 描述    1  已修复   所有版本   已修复(=1.1)   命令行启动-P模式不被识别     2  已修复   单机版   已修复(=1.1)   如果docker运行环境配置较差（例如超低配置的虚拟机），ES启动时间过久导致分析程序无法正常工作     3  已修复   单机版，集群-公网版   已修复(=1.2)   当前环境下抓到的包丢包率较大     4  已修复   单机版，集群-公网版   已修复(=1.</description>
    </item>
    
    <item>
      <title>安全</title>
      <link>/%E7%94%A8%E6%B3%95/security/</link>
      <pubDate>Mon, 02 Apr 2018 21:57:07 +0800</pubDate>
      
      <guid>/%E7%94%A8%E6%B3%95/security/</guid>
      <description> 场景 1.使用流量发现WEBSHELL
待更新  2.使用流量进行攻击检测
待更新  3.使用流量进行登录监控
待更新  4.使用流量进行用户行为画像
待更新  5.使用流量追踪羊毛党
待更新  </description>
    </item>
    
    <item>
      <title>FAQ</title>
      <link>/%E9%99%84%E5%BD%95/faq/</link>
      <pubDate>Mon, 02 Apr 2018 21:55:52 +0800</pubDate>
      
      <guid>/%E9%99%84%E5%BD%95/faq/</guid>
      <description> 常见问题  怎么解决使用了HTTPS证书后无法获取加密的流量
将HTTPS部署到反向代理上，通过反向代理之后卸载TLS流量；此时在通过在反向代理上利用端口过滤的方式拿出所需要的解密后的流量  是否支持GZIP?
支持，默认情况下，对于静态资源的response.body会被drop掉内容。对于超长的会截断内容  kafka资源数量估计(kafka分区数，kafka broker数量)
每个请求平均为1k，那么TPS * 1k = 实时流量 kafka broker数量 约等于 实时流量/kafka带宽/每机器分区数  ElasticSearch 资源需求
ElasticSearch 内存限制了查询的数据量 ElasticSearch 硬盘限制存储的数据量  修改单机版ElasticSearch内存限制
ps -ef 查看容器id 进入docker容器 docker exec -it &amp;lt;id&amp;gt; /bin/sh kill elasticsearch进程 修改/home/elasticsearch/elasticsearch/config/jvm.options文件字段: -Xmx=1G -Xms=1G 保存后重新启动ElasticSearch  过滤器
目前端口过滤器用，在集群版里支持域名过滤器   </description>
    </item>
    
    <item>
      <title>联系我们</title>
      <link>/%E9%99%84%E5%BD%95/contact/</link>
      <pubDate>Mon, 02 Apr 2018 21:55:52 +0800</pubDate>
      
      <guid>/%E9%99%84%E5%BD%95/contact/</guid>
      <description>关于我们 河马安全团队专注WEB安全研究，擅长webshell查杀技术。
邮箱: q@shellpub.com</description>
    </item>
    
    <item>
      <title>数据接口</title>
      <link>/%E7%94%A8%E6%B3%95/data_interface/</link>
      <pubDate>Mon, 02 Apr 2018 21:57:08 +0100</pubDate>
      
      <guid>/%E7%94%A8%E6%B3%95/data_interface/</guid>
      <description>近期开放</description>
    </item>
    
    <item>
      <title>分析接口</title>
      <link>/%E7%94%A8%E6%B3%95/ana_interface/</link>
      <pubDate>Mon, 02 Apr 2018 21:55:52 +0800</pubDate>
      
      <guid>/%E7%94%A8%E6%B3%95/ana_interface/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>